{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SOMA to label unlabeled mocaps\n",
    "\n",
    "We roughly base this off of the two SOMA tutorials: [Tutorial 1](https://github.com/nghorbani/soma/blob/main/src/tutorials/run_soma_on_soma_dataset.ipynb) and [Tutorial 2](https://github.com/nghorbani/soma/blob/main/src/tutorials/label_priming.ipynb).\n",
    "\n",
    "Reading the [definitions](https://github.com/nghorbani/soma/tree/main/src/tutorials#definitions) of terminology is recommended.\n",
    "\n",
    "We will be using a pre-trained SOMA model called the \"SuperSet\" to label our unlabeled motioin capture data. The SuperSet trains a body model with 89 markers placed around the body, and thus will label our unlabeled mocap data by matching our unlabeled markers to a subset of the 89 markers. If we have an unlabeled marker that does not correspond to a marker on the SuperSet, the behavior is undefined -- either that marker will be unlabeled (marked as ghost points/discarded), or it will be labelled with some nearby marker label. This imperfect labelling can lead to downstream errors when trying to fit the SMPL model to the labelled mocap data.\n",
    "\n",
    "It is possible to train a new SOMA model, for a different marker layout (specifically a marker layout that does not fit a subset of the SuperSet), please check this [README](https://github.com/nghorbani/soma/tree/main/src/tutorials/README.md) and Tutorial 1 for information on this. As per the note in Tutorial 1, the AMASS marker noise model and the CAESAR parameters both help the model training, but neither are publicly available due to licensing. Thus it is more optimal to use the pretrained models. As such, we will not be covering model training in this tutorial.\n",
    "\n",
    "Conceptually, this is how the SOMA training works (see [this paper](https://arxiv.org/pdf/2110.04431.pdf) for more details):\n",
    "- Goal: to label unlabeled mocap data for a specific *markerlayout*\n",
    "- First, we take a single frame from a single trial of our unlabeled mocap data\n",
    "  - one frame needed per subject, since each subject has a unique body -- and thus unique markerlayouts/point clouds -- thus a unique body model\n",
    "- This frame is labelled\n",
    "- This labelled frame is MoSHed to get a SMPL-X body model for that specific subject\n",
    "- virtual markers corresponding to our markerlayout are automotically placed on this SMPL-X body\n",
    "- This SMPL body model is animated by AMASS motions\n",
    "  - AMASS dataset has many actions saved in SMPL format, which allows us to have our subject-specific body-model 'perform' many actions\n",
    "- Thus a large repository of labeled mocap data is synthesized, data which is specific to our subject and our markerlayout\n",
    "- Real noise data is added to this synthetic data\n",
    "- occlusions and ghost points also added\n",
    "- SOMA model is trained on this synthetic data, where the model is given the input of a synthetic unlabeled point cloud and learns to output the corresponding labels\n",
    "- Transformers multiple self-attention units are used to learn the spatial structure of the 3d body, as well as an optimal transport layer to encode the natural constraints of the human body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soma3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
